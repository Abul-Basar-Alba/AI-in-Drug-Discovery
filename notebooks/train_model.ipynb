{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b993cda",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Add src to path\u001b[39;00m\n\u001b[32m     12\u001b[39m sys.path.append(\u001b[33m'\u001b[39m\u001b[33m../src\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DrugDataLoader, TextDataProcessor\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataPreprocessor\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrain_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DrugDiscoveryModels\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/AE587D7D587D44DD/5Th_Semester/CIT-316(AI Sessional )/AI-Assignment/notebooks/../src/data/data_loader.py:11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, List, Tuple, Optional\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mDrugDataLoader\u001b[39;00m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data.data_loader import DrugDataLoader, TextDataProcessor\n",
    "from data.preprocessing import DataPreprocessor\n",
    "from models.train_models import DrugDiscoveryModels\n",
    "from models.deep_learning import DeepLearningModels\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úì All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd70514",
   "metadata": {},
   "source": [
    "## Step 1: Generate Sample Data\n",
    "\n",
    "First, let's generate our synthetic drug discovery dataset with 10,000+ samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a47fc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate datasets if they don't exist\n",
    "from data.generate_data import generate_all_datasets\n",
    "import os\n",
    "\n",
    "if not os.path.exists('../data/raw/drug_data.csv'):\n",
    "    print(\"Generating datasets... This may take a few minutes.\")\n",
    "    generate_all_datasets(n_samples=10000, n_images=500)\n",
    "else:\n",
    "    print(\"Datasets already exist. Skipping generation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0273be8f",
   "metadata": {},
   "source": [
    "## Step 2: Load Multiple Data Sources\n",
    "\n",
    "Load and merge CSV, JSON, and image feature data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04565fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "loader = DrugDataLoader(data_dir='../data/raw')\n",
    "\n",
    "# Load and merge all data sources\n",
    "df = loader.merge_all_data(\n",
    "    csv_file='drug_data.csv',\n",
    "    json_file='drug_interactions.json',\n",
    "    use_images=True\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6f1807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and missing values\n",
    "print(\"Data Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "missing = df.isnull().sum()\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e79a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "target_counts = df['target'].value_counts()\n",
    "plt.bar(['Not Effective (0)', 'Effective (1)'], target_counts.values, color=['#FF6B6B', '#4ECDC4'])\n",
    "plt.title('Drug Effectiveness Distribution', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Class')\n",
    "for i, v in enumerate(target_counts.values):\n",
    "    plt.text(i, v + 50, str(v), ha='center', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nClass balance: {target_counts[1]/(target_counts[0]+target_counts[1])*100:.1f}% effective drugs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b834469e",
   "metadata": {},
   "source": [
    "## Step 3: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf87b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"Statistical Summary of Numerical Features:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d92ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distributions of key features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "key_features = ['molecular_weight', 'logP', 'bioavailability', \n",
    "                'efficacy_score', 'safety_score', 'solubility']\n",
    "\n",
    "for idx, feature in enumerate(key_features):\n",
    "    row = idx // 3\n",
    "    col = idx % 3\n",
    "    \n",
    "    axes[row, col].hist(df[feature].dropna(), bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    axes[row, col].set_title(f'{feature} Distribution', fontweight='bold')\n",
    "    axes[row, col].set_xlabel(feature)\n",
    "    axes[row, col].set_ylabel('Frequency')\n",
    "    axes[row, col].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fc80ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(correlation_matrix, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Heatmap', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab753378",
   "metadata": {},
   "source": [
    "## Step 4: Data Preprocessing & Feature Engineering\n",
    "\n",
    "Apply comprehensive preprocessing:\n",
    "- Handle missing values\n",
    "- Create interaction features\n",
    "- Create polynomial features\n",
    "- Encode categorical variables\n",
    "- Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3ffca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor\n",
    "preprocessor = DataPreprocessor()\n",
    "\n",
    "# Apply feature engineering pipeline\n",
    "df_processed = preprocessor.feature_engineering_pipeline(df, target_col='target')\n",
    "\n",
    "print(f\"\\nProcessed dataset shape: {df_processed.shape}\")\n",
    "print(f\"Number of features created: {df_processed.shape[1] - df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280d807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any remaining missing values\n",
    "print(\"Missing values after preprocessing:\")\n",
    "print(df_processed.isnull().sum().sum())\n",
    "\n",
    "if df_processed.isnull().sum().sum() > 0:\n",
    "    print(\"\\nFilling any remaining missing values...\")\n",
    "    df_processed = df_processed.fillna(df_processed.median(numeric_only=True))\n",
    "    df_processed = df_processed.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414a2dfc",
   "metadata": {},
   "source": [
    "## Step 5: Train Multiple ML Models\n",
    "\n",
    "Train and compare:\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- Gradient Boosting\n",
    "- XGBoost\n",
    "- SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8250c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model trainer\n",
    "ml_models = DrugDiscoveryModels(random_state=42)\n",
    "\n",
    "# Prepare data\n",
    "X_train, X_test, y_train, y_test = ml_models.prepare_data(df_processed, target_col='target', test_size=0.2)\n",
    "\n",
    "# Save feature names for later\n",
    "feature_names = X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ebef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all ML models\n",
    "results = ml_models.train_all_models(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523fdb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "results_df = pd.DataFrame([\n",
    "    {\n",
    "        'Model': metrics['model_name'],\n",
    "        'Accuracy': metrics['accuracy'],\n",
    "        'Precision': metrics['precision'],\n",
    "        'Recall': metrics['recall'],\n",
    "        'F1 Score': metrics['f1_score'],\n",
    "        'ROC AUC': metrics['roc_auc']\n",
    "    }\n",
    "    for metrics in results.values()\n",
    "])\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Accuracy comparison\n",
    "results_df.plot(x='Model', y='Accuracy', kind='bar', ax=axes[0], color='steelblue', legend=False)\n",
    "axes[0].set_title('Model Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_xlabel('')\n",
    "axes[0].set_ylim([0.7, 1.0])\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# All metrics comparison\n",
    "metrics_to_plot = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.15\n",
    "\n",
    "for idx, metric in enumerate(metrics_to_plot):\n",
    "    axes[1].bar(x + idx * width, results_df[metric], width, label=metric)\n",
    "\n",
    "axes[1].set_xlabel('Model')\n",
    "axes[1].set_ylabel('Score')\n",
    "axes[1].set_title('All Metrics Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xticks(x + width * 2)\n",
    "axes[1].set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_ylim([0.7, 1.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bbee9f",
   "metadata": {},
   "source": [
    "## Step 6: Train Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9842d540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DL model\n",
    "dl_model = DeepLearningModels(random_state=42)\n",
    "\n",
    "# Further split training data for validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_dl, X_val_dl, y_train_dl, y_val_dl = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"DL Training set: {X_train_dl.shape}\")\n",
    "print(f\"DL Validation set: {X_val_dl.shape}\")\n",
    "print(f\"DL Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce8b7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MLP model\n",
    "dl_metrics = dl_model.train_mlp(\n",
    "    X_train_dl, y_train_dl, \n",
    "    X_val_dl, y_val_dl,\n",
    "    epochs=100,\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d0de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig = dl_model.plot_training_history()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f88bb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate DL model on test set\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "y_pred_dl = dl_model.predict(X_test)\n",
    "y_pred_proba_dl = dl_model.predict_proba(X_test)\n",
    "\n",
    "print(\"Deep Learning Model - Test Set Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_dl):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_dl, target_names=['Not Effective', 'Effective']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab9635c",
   "metadata": {},
   "source": [
    "## Step 7: Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdb3fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Get predictions from best ML model\n",
    "best_ml_model = ml_models.best_model\n",
    "y_pred_ml = best_ml_model.predict(X_test)\n",
    "\n",
    "# Create confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# ML Model confusion matrix\n",
    "cm_ml = confusion_matrix(y_test, y_pred_ml)\n",
    "sns.heatmap(cm_ml, annot=True, fmt='d', cmap='Blues', ax=axes[0], cbar=False)\n",
    "axes[0].set_title(f'{ml_models.best_model_name} Confusion Matrix', fontweight='bold')\n",
    "axes[0].set_ylabel('True Label')\n",
    "axes[0].set_xlabel('Predicted Label')\n",
    "axes[0].set_xticklabels(['Not Effective', 'Effective'])\n",
    "axes[0].set_yticklabels(['Not Effective', 'Effective'])\n",
    "\n",
    "# DL Model confusion matrix\n",
    "cm_dl = confusion_matrix(y_test, y_pred_dl)\n",
    "sns.heatmap(cm_dl, annot=True, fmt='d', cmap='Greens', ax=axes[1], cbar=False)\n",
    "axes[1].set_title('Deep Neural Network Confusion Matrix', fontweight='bold')\n",
    "axes[1].set_ylabel('True Label')\n",
    "axes[1].set_xlabel('Predicted Label')\n",
    "axes[1].set_xticklabels(['Not Effective', 'Effective'])\n",
    "axes[1].set_yticklabels(['Not Effective', 'Effective'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57e5999",
   "metadata": {},
   "source": [
    "## Step 8: Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b960693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from best model\n",
    "if hasattr(ml_models.best_model, 'feature_importances_'):\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': ml_models.best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False).head(20)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(range(len(importance_df)), importance_df['importance'], color='coral')\n",
    "    plt.yticks(range(len(importance_df)), importance_df['feature'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title(f'Top 20 Feature Importance - {ml_models.best_model_name}', \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"{ml_models.best_model_name} does not support feature importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db9d1c2",
   "metadata": {},
   "source": [
    "## Step 9: ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439ee428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot ROC for each ML model\n",
    "for model_name, model in ml_models.models.items():\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.3f})', linewidth=2)\n",
    "\n",
    "# Plot ROC for DL model\n",
    "fpr_dl, tpr_dl, _ = roc_curve(y_test, y_pred_proba_dl)\n",
    "roc_auc_dl = auc(fpr_dl, tpr_dl)\n",
    "plt.plot(fpr_dl, tpr_dl, label=f'Deep Neural Network (AUC = {roc_auc_dl:.3f})', \n",
    "         linewidth=2, linestyle='--')\n",
    "\n",
    "# Plot random classifier\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier', linewidth=1)\n",
    "\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curves - All Models', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2489ccf",
   "metadata": {},
   "source": [
    "## Step 10: Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaa9ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all ML models\n",
    "ml_models.save_models(output_dir='../models')\n",
    "\n",
    "# Save DL model\n",
    "dl_model.save_model('../models/deep_neural_network.keras')\n",
    "\n",
    "# Save preprocessor\n",
    "import joblib\n",
    "joblib.dump(preprocessor, '../models/preprocessor.pkl')\n",
    "\n",
    "# Save feature names\n",
    "joblib.dump(feature_names, '../models/feature_names.pkl')\n",
    "\n",
    "print(\"\\n‚úì All models and preprocessor saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5043fc",
   "metadata": {},
   "source": [
    "## Step 11: Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd20585",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"FINAL MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Combine all results\n",
    "all_results = []\n",
    "\n",
    "for model_name, metrics in results.items():\n",
    "    all_results.append({\n",
    "        'Model': metrics['model_name'],\n",
    "        'Type': 'ML',\n",
    "        'Accuracy': f\"{metrics['accuracy']:.4f}\",\n",
    "        'F1 Score': f\"{metrics['f1_score']:.4f}\",\n",
    "        'ROC AUC': f\"{metrics['roc_auc']:.4f}\"\n",
    "    })\n",
    "\n",
    "all_results.append({\n",
    "    'Model': 'Deep Neural Network',\n",
    "    'Type': 'DL',\n",
    "    'Accuracy': f\"{accuracy_score(y_test, y_pred_dl):.4f}\",\n",
    "    'F1 Score': f\"{f1_score(y_test, y_pred_dl):.4f}\",\n",
    "    'ROC AUC': f\"{roc_auc_score(y_test, y_pred_proba_dl):.4f}\"\n",
    "})\n",
    "\n",
    "summary_df = pd.DataFrame(all_results)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"üèÜ BEST MODEL: {ml_models.best_model_name}\")\n",
    "print(f\"   Accuracy: {ml_models.best_score:.4f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìä Dataset Statistics:\")\n",
    "print(f\"   Total samples: {len(df):,}\")\n",
    "print(f\"   Training samples: {len(X_train):,}\")\n",
    "print(f\"   Test samples: {len(X_test):,}\")\n",
    "print(f\"   Original features: {len(df.columns)}\")\n",
    "print(f\"   Engineered features: {len(feature_names)}\")\n",
    "\n",
    "print(\"\\n‚úÖ Training pipeline completed successfully!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"   1. Run manual_drug_test.py to test with your own drug data\")\n",
    "print(\"   2. Models are saved in ../models/ directory\")\n",
    "print(\"   3. Use the best model for predictions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
